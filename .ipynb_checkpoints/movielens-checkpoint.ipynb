{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession.builder.appName(\"practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.dat  ratings.dat  README  users.dat\n"
     ]
    }
   ],
   "source": [
    "!ls ml-1m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Ratings and Movie Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(movie_id=1193, rating=5.0, user=1)]\n",
      "[Row(movie_id=1193, rating=5.0, user=1)]\n"
     ]
    }
   ],
   "source": [
    "def parse_ratings(line):\n",
    "    fields = line.split(\"::\")\n",
    "    return Row(user=int(fields[0]), movie_id=int(fields[1]), rating=float(fields[2]))\n",
    "\n",
    "def parse_movie_names(line):\n",
    "    f = line.split(\"::\")\n",
    "    return Row(movie_id=int(f[0]), name=str(f[1]))\n",
    "\n",
    "# create rdd and parse it using the row object\n",
    "rating_rdd = spark.sparkContext.textFile('ml-1m/ratings.dat')\n",
    "rating_rdd = rating_rdd.map(parse_ratings)\n",
    "\n",
    "movies_rdd = spark.sparkContext.textFile('ml-1m/movies.dat')\n",
    "movie_names_rdd = movies_rdd.map(parse_movie_names)\n",
    "print(rating_rdd.take(1))\n",
    "\n",
    "# create dataframe using rdd\n",
    "ratings = spark.createDataFrame(rating_rdd)\n",
    "movies = spark.createDataFrame(movie_names)\n",
    "print(ratings.head(1))\n",
    "\n",
    "# Use take() with rdd and head() with dataframe to see what's happening\n",
    "assert rating_rdd.take(1) == ratings.head(1)\n",
    "assert ratings.take(1) == ratings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- user: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie_id', 'rating', 'user']\n",
      "[('movie_id', 'bigint'), ('rating', 'double'), ('user', 'bigint')]\n",
      "+--------+------+----+\n",
      "|movie_id|rating|user|\n",
      "+--------+------+----+\n",
      "|    1193|   5.0|   1|\n",
      "|     661|   3.0|   1|\n",
      "|     914|   3.0|   1|\n",
      "|    3408|   4.0|   1|\n",
      "|    2355|   5.0|   1|\n",
      "|    1197|   3.0|   1|\n",
      "|    1287|   5.0|   1|\n",
      "|    2804|   5.0|   1|\n",
      "|     594|   4.0|   1|\n",
      "|     919|   4.0|   1|\n",
      "|     595|   5.0|   1|\n",
      "|     938|   4.0|   1|\n",
      "|    2398|   4.0|   1|\n",
      "|    2918|   4.0|   1|\n",
      "|    1035|   5.0|   1|\n",
      "|    2791|   4.0|   1|\n",
      "|    2687|   3.0|   1|\n",
      "|    2018|   4.0|   1|\n",
      "|    3105|   5.0|   1|\n",
      "|    2797|   4.0|   1|\n",
      "+--------+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ratings.columns)\n",
    "print(ratings.dtypes)\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+-------+\n",
      "|movie_id|rating|user|%_score|\n",
      "+--------+------+----+-------+\n",
      "|    1193|   5.0|   1|  100.0|\n",
      "|     661|   3.0|   1|   60.0|\n",
      "|     914|   3.0|   1|   60.0|\n",
      "|    3408|   4.0|   1|   80.0|\n",
      "|    2355|   5.0|   1|  100.0|\n",
      "+--------+------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create new column or modify existing in place using withColumn\n",
    "# use withColumnRenamed to rename a column\n",
    "ratings.withColumn(\"score\", 100 * ratings.rating / 5.0).withColumnRenamed(\"score\", \"%_score\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 movies with at least 100 reviews using dataframe api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)', 4.560509554140127, 628)\n",
      "('Shawshank Redemption, The (1994)', 4.554557700942973, 2227)\n",
      "('Godfather, The (1972)', 4.524966261808367, 2223)\n",
      "('Close Shave, A (1995)', 4.52054794520548, 657)\n",
      "('Usual Suspects, The (1995)', 4.517106001121705, 1783)\n",
      "(\"Schindler's List (1993)\", 4.510416666666667, 2304)\n",
      "('Wrong Trousers, The (1993)', 4.507936507936508, 882)\n",
      "('Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)', 4.491489361702127, 470)\n",
      "('Raiders of the Lost Ark (1981)', 4.477724741447892, 2514)\n",
      "('Rear Window (1954)', 4.476190476190476, 1050)\n"
     ]
    }
   ],
   "source": [
    "# calculate aggregate statistics\n",
    "avg_rating = ratings.groupby(\"movie_id\").avg(\"rating\")\n",
    "num_rating = ratings.groupby(\"movie_id\").count()\n",
    "\n",
    "# join stats and movie name\n",
    "avg_and_count = avg_rating.join(num_rating, \"movie_id\")\n",
    "summary = movies.join(avg_and_count, \"movie_id\")\n",
    "summary = summary.filter(summary[\"count\"] > 100)\n",
    "\n",
    "# sort / can also use sort notation --> df.sort(df.columnName.desc())\n",
    "top_10_api = summary.orderBy(\"avg(rating)\", ascending=False).take(10)\n",
    "\n",
    "# print results (could also just use a show() here)\n",
    "for row in top_10_api:\n",
    "    print((row.name, row['avg(rating)'], row['count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 movies with at least 100 reviews using sql api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)', 4.560509554140127, 628)\n",
      "('Shawshank Redemption, The (1994)', 4.554557700942973, 2227)\n",
      "('Godfather, The (1972)', 4.524966261808367, 2223)\n",
      "('Close Shave, A (1995)', 4.52054794520548, 657)\n",
      "('Usual Suspects, The (1995)', 4.517106001121705, 1783)\n",
      "(\"Schindler's List (1993)\", 4.510416666666667, 2304)\n",
      "('Wrong Trousers, The (1993)', 4.507936507936508, 882)\n",
      "('Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)', 4.491489361702127, 470)\n",
      "('Raiders of the Lost Ark (1981)', 4.477724741447892, 2514)\n",
      "('Rear Window (1954)', 4.476190476190476, 1050)\n"
     ]
    }
   ],
   "source": [
    "# create temporary tables\n",
    "ratings.createOrReplaceTempView(\"ratings\")\n",
    "movies.createOrReplaceTempView(\"movies\")\n",
    "\n",
    "# run sql query which returns a dataframe\n",
    "result = spark.sql(\n",
    "    ''' \n",
    "    SELECT name, AVG(rating), COUNT(rating)\n",
    "    FROM ratings INNER JOIN movies ON ratings.movie_id = movies.movie_id \n",
    "    GROUP BY name\n",
    "    HAVING COUNT(rating) > 100\n",
    "    '''\n",
    ")\n",
    "\n",
    "# for some reason can't do both having and order by in spark sql\n",
    "# can also use sort notation --> df.sort(df.columnName.desc())\n",
    "result = result.orderBy(\"avg(rating)\", ascending= False)\n",
    "\n",
    "# convert dataframe into a list of rows (could also just use a show() here)\n",
    "top_10_sql = result.take(10)\n",
    "for row in top_10_sql:\n",
    "    print((row.name, row['avg(rating)'], row['count(rating)']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
